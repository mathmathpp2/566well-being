{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from webbrowser import get\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "from models import *\n",
    "import logging\n",
    "from pretty_logger import get_logger\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define subset (ignore all other data)\n",
    "ema = [f\"Y{i}\" for i in range(1, 8, 1)]\n",
    "physical = [f\"P{i}\" for i in range(1, 5, 1)]\n",
    "social = [f\"S{i}\" for i in range(1, 8, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(datafile)\n",
    "df[\"date\"] = pd.to_datetime(df[\"day_survey\"])\n",
    "df[\"C\"] = df[\"date\"].apply(\n",
    "    lambda date: (\n",
    "        COVIDStatus.POST_COVID if date > date_covid else COVIDStatus.PRE_COVID\n",
    "    )\n",
    ")\n",
    "df_head = df.head(5).copy()\n",
    "\n",
    "df.rename(columns=reverse_ema_dictionary, inplace=True)\n",
    "df.set_index([\"uid\", \"date\"], inplace=True)\n",
    "\n",
    "subset = ema + physical + social + sleep + [\"C\"]\n",
    "df = df[subset]\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "sets_df = pd.read_parquet(sets_file, engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Y4',\n",
       " 'Y1',\n",
       " 'Z3',\n",
       " 'Y6',\n",
       " 'P2',\n",
       " 'Z1',\n",
       " 'S1',\n",
       " 'Y2',\n",
       " 'Y5',\n",
       " 'S4',\n",
       " 'S2',\n",
       " 'C',\n",
       " 'Z2',\n",
       " 'S7',\n",
       " 'Y7',\n",
       " 'Y3',\n",
       " 'P3']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_emas = list(set(ema_dictionary.keys()).difference(set([\"Y2\", \"Y3\"])))\n",
    "skip_treatments = list(\n",
    "    set(subset).difference(\n",
    "        set(\n",
    "            [\n",
    "                \"P1\",\n",
    "                \"P4\",\n",
    "                # \"S1\",\n",
    "                # \"S2\",\n",
    "                \"S3\",\n",
    "                # \"S4\",\n",
    "                \"S5\",\n",
    "                \"S6\",\n",
    "                # \"Z1\",\n",
    "                # \"Z2\",\n",
    "                # \"Z3\",\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "skip_treatments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[\u001b[38;5;192m2024-05-28 16:10:10\u001b[0m.\u001b[33m644\u001b[0m] - \u001b[32mmodelslog-\u001b[0m \u001b[32mINFO\u001b[0m \u001b[35mN/A-\u001b[0m \u001b[34m1895262791.py:\u001b[0m \u001b[35m30\u001b[0m \u001b[37m[<module>]:\u001b[0m \u001b[32m\u001b[38;5;222mFitting\n",
      "treatment: P1:excercise (seconds), outcome: Y2:phq4_score, adjustment set={'P4', 'P2', 'S1', 'S4', 'S3', 'S6', 'S2'}\u001b[0m\u001b[0m\n",
      "[\u001b[38;5;192m2024-05-28 16:10:10\u001b[0m.\u001b[33m646\u001b[0m] - \u001b[32mmodelslog-\u001b[0m \u001b[32mINFO\u001b[0m \u001b[35mN/A-\u001b[0m \u001b[34m1895262791.py:\u001b[0m \u001b[35m31\u001b[0m \u001b[37m[<module>]:\u001b[0m \u001b[32m\u001b[38;5;222mMedian of P1 10.9634\u001b[0m\u001b[0m\n",
      "[\u001b[38;5;192m2024-05-28 16:11:31\u001b[0m.\u001b[33m186\u001b[0m] - \u001b[32mmodelslog-\u001b[0m \u001b[32mINFO\u001b[0m \u001b[35mN/A-\u001b[0m \u001b[34m1895262791.py:\u001b[0m \u001b[35m41\u001b[0m \u001b[37m[<module>]:\u001b[0m \u001b[32m\u001b[38;5;222mpre_rsq train=0.5439242796475374, pre_rsq test=-0.8098204271218932\n",
      "pre mae test =2.254140081441697\n",
      "post_rsq train=0.5171966643519755, post_rsq test=-0.8515877005201655\n",
      "\u001b[0m\u001b[0m\n",
      "[\u001b[38;5;192m2024-05-28 16:11:31\u001b[0m.\u001b[33m187\u001b[0m] - \u001b[32mmodelslog-\u001b[0m \u001b[32mINFO\u001b[0m \u001b[35mN/A-\u001b[0m \u001b[34m1895262791.py:\u001b[0m \u001b[35m46\u001b[0m \u001b[37m[<module>]:\u001b[0m \u001b[32m\u001b[38;5;222m-----------------------------------------------------\n",
      "\u001b[0m\u001b[0m\n",
      "[\u001b[38;5;192m2024-05-28 16:11:31\u001b[0m.\u001b[33m188\u001b[0m] - \u001b[32mmodelslog-\u001b[0m \u001b[32mINFO\u001b[0m \u001b[35mN/A-\u001b[0m \u001b[34m1895262791.py:\u001b[0m \u001b[35m30\u001b[0m \u001b[37m[<module>]:\u001b[0m \u001b[32m\u001b[38;5;222mFitting\n",
      "treatment: P4:sports (hours), outcome: Y2:phq4_score, adjustment set={'P2', 'S1', 'S4', 'S5', 'S3', 'P3'}\u001b[0m\u001b[0m\n",
      "[\u001b[38;5;192m2024-05-28 16:11:31\u001b[0m.\u001b[33m190\u001b[0m] - \u001b[32mmodelslog-\u001b[0m \u001b[32mINFO\u001b[0m \u001b[35mN/A-\u001b[0m \u001b[34m1895262791.py:\u001b[0m \u001b[35m31\u001b[0m \u001b[37m[<module>]:\u001b[0m \u001b[32m\u001b[38;5;222mMedian of P4 0.08325\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# index = 17\n",
    "# model_row = sets_df.iloc[index]\n",
    "\n",
    "alphas = [0.2, 1, 2]\n",
    "n_estimatorss = [400]\n",
    "\n",
    "for n_estimators in n_estimatorss:\n",
    "    for alpha in alphas:\n",
    "        for index, model_row in sets_df.iterrows():\n",
    "            already_fitted_sets = []\n",
    "\n",
    "            covariate_set = CovariateSet(\n",
    "                row=model_row,\n",
    "                data=df,\n",
    "                outcomes_to_skip=skip_emas,\n",
    "                treatments_to_skip=skip_treatments,\n",
    "            )\n",
    "\n",
    "            if not covariate_set.valid_set:\n",
    "                logger.debug(f\"Skipping {covariate_set} (no valid set)\")\n",
    "                continue\n",
    "\n",
    "            if covariate_set.set_to_fit in already_fitted_sets:\n",
    "                logger.info(\n",
    "                    f\"Skipping {covariate_set} (already did {covariate_set.set_to_fit})\"\n",
    "                )\n",
    "                continue\n",
    "            already_fitted_sets.append(covariate_set.set_to_fit)\n",
    "\n",
    "            logger.info(f\"Fitting\\n{covariate_set!r}\")\n",
    "            logger.info(\n",
    "                f\"Median of {covariate_set.treatment} {df[covariate_set.treatment].median()}\"\n",
    "            )\n",
    "            wbm = WBKernelModel(\n",
    "                data=df,\n",
    "                treatment=covariate_set.treatment,\n",
    "                outcome=covariate_set.outcome,\n",
    "                separating_set=covariate_set.restricted_adjustment_set,\n",
    "                name=f\"row:{index}\",\n",
    "            )\n",
    "            logger.info(\n",
    "                f\"pre_rsq train={wbm.pre_r_squared[0]}, pre_rsq test={wbm.pre_r_squared[1]}\\n\"\n",
    "                f\"pre mae test ={wbm.pre_r_squared[2]}\\n\"\n",
    "                f\"post_rsq train={wbm.post_r_squared[0]}, post_rsq test={wbm.post_r_squared[1]}\\n\"\n",
    "            )\n",
    "            logger.info(\n",
    "                \"-----------------------------------------------------\\n\"\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
