{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "from typing import Union, List\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from pathlib import Path\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_prior_days = 10\n",
    "date_covid = datetime(2020, 3, 1)\n",
    "# rough date\n",
    "date_vaccine = datetime(2021, 4, 1)\n",
    "\n",
    "class WBModelType(enum.Enum):\n",
    "    LINEAR = 1\n",
    "\n",
    "class SplitMethod(enum.Enum):\n",
    "    MEDIAN = 1\n",
    "\n",
    "class COVIDStatus(enum.Enum):\n",
    "    PRE_COVID = 0\n",
    "    POST_COVID = 1\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.name}\"\n",
    "\n",
    "ema_dictionary = {\n",
    "    \"Y1\": \"pam\",\n",
    "    \"Y2\": \"phq2_score\",\n",
    "    \"Y3\": \"phq4_score\",\n",
    "    \"Y4\": \"gad2_score\",\n",
    "    \"Y5\": \"social_level\",\n",
    "    \"Y6\": \"sse_score\",\n",
    "    \"Y7\": \"stress\",\n",
    "}\n",
    "reverse_ema_dictionary = {v: k for k, v in ema_dictionary.items()}\n",
    "\n",
    "physical_dictionary = {\n",
    "    \"P1\": \"excercise\",\n",
    "    \"P2\": \"studying\",\n",
    "    \"P3\": \"in house\",\n",
    "    \"P4\": \"sports\",\n",
    "}\n",
    "social_dictionary = {\n",
    "    \"S1\": \"traveling\",\n",
    "    \"S2\": \"distance traveled\",\n",
    "    \"S3\": \"time in social location\",\n",
    "    \"S4\": \"visits\",\n",
    "    \"S5\": \"duration unlocked phone in social locations\",\n",
    "    \"S6\": \"frequency of unlocked phone in social locations\",\n",
    "    \"S7\": \"motion at social locations\",\n",
    "}\n",
    "\n",
    "sleep_dictionary = {\n",
    "    \"Z1\": \"sleep_duration\",\n",
    "    \"Z2\": \"sleep start time\",\n",
    "    \"Z3\": \"sleep end time\",\n",
    "}\n",
    "\n",
    "\n",
    "demographics_dictionary = {\n",
    "    \"D1\": \"gender\",\n",
    "    \"D2\": \"race\",\n",
    "    \"D3\": \"os\",\n",
    "    \"D4\": \"cohort year\",\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "full_dictionary = (\n",
    "    physical_dictionary | social_dictionary | sleep_dictionary | ema_dictionary | {'C': COVIDStatus}\n",
    ")\n",
    "\n",
    "ema = [f\"Y{i}\" for i in range(1, 8, 1)]\n",
    "physical = [f\"P{i}\" for i in range(1, 5, 1)]\n",
    "social = [f\"S{i}\" for i in range(1, 8, 1)]\n",
    "sleep = [f\"Z{i}\" for i in range(1, 4, 1)]\n",
    "\n",
    "datafile = \"../data/features_v3.csv\"\n",
    "# _longest is actually shorter\n",
    "sets_file = \"../2.causal discovery/pc_ici_longest.parquet\"\n",
    "#sets_file = \"../2.causal discovery/pc_ici.parquet\"\n",
    "\n",
    "df = pd.read_csv(datafile)\n",
    "df[\"date\"] = pd.to_datetime(df[\"day_survey\"])\n",
    "df['C'] = df['date'].apply(lambda date: COVIDStatus.POST_COVID if date > date_covid else COVIDStatus.PRE_COVID)\n",
    "\n",
    "df_head = df.head(5).copy()\n",
    "\n",
    "df.rename(columns=reverse_ema_dictionary, inplace=True)\n",
    "df.set_index([\"uid\", \"date\"], inplace=True)\n",
    "df.dropna(subset=ema + physical + social + sleep, inplace=True)\n",
    "\n",
    "sets_df = pd.read_parquet(sets_file, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RandomForestModelBuilder:\n",
    "    def __init__(self, data, outcome, covariates):\n",
    "        self.data = data\n",
    "        self.outcome = outcome\n",
    "        self.covariates = covariates\n",
    "\n",
    "    def fit_random_forest(self, test_size=0.2, random_state=None, n_estimators=100, max_depth=None):\n",
    "        # Extract the X (covariates) and y (outcome) from the data\n",
    "        X = self.data[self.covariates]\n",
    "        y = self.data[self.outcome]\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "        model = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('regressor', RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state))\n",
    "        ])\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict the outcome on the training and testing data\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        r2_train = r2_score(y_train, y_pred_train)\n",
    "        r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "        # Return the fitted model and the R^2 scores for training and testing sets\n",
    "        return model, (r2_train, r2_test)\n",
    "\n",
    "\n",
    "class LinearModelBuilder:\n",
    "    def __init__(self, data, outcome, covariates):\n",
    "        self.data = data\n",
    "        self.outcome = outcome\n",
    "        self.covariates = covariates\n",
    "\n",
    "    def fit_linear_model(self, test_size=0.2, random_state=None, alpha=1.0):\n",
    "        # Extract the X (covariates) and y (outcome) from the data\n",
    "        X = self.data[self.covariates]\n",
    "        y = self.data[self.outcome]\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "        # Create and fit the linear regression model\n",
    "        model = KernelRidge(kernel='linear', alpha=alpha)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict the outcome on the training and testing data\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        r2_train = r2_score(y_train, y_pred_train)\n",
    "        r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "        # Return the fitted model and the R^2 scores for training and testing sets\n",
    "        self.model = model\n",
    "        return model, r2_train, r2_test\n",
    "\n",
    "    def fit_gaussian_kernel_model(self, test_size=0.2, random_state=None, alpha=1.0, gamma=None):\n",
    "        # Extract the X (covariates) and y (outcome) from the data\n",
    "        X = self.data[self.covariates]\n",
    "        y = self.data[self.outcome]\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "        model = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('regressor', KernelRidge(kernel='rbf', alpha=alpha, gamma=gamma))\n",
    "        ])\n",
    "        model.fit(X_train, y_train)\n",
    "        # Create and fit the Gaussian kernel regression model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict the outcome on the training and testing data\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        r2_train = r2_score(y_train, y_pred_train)\n",
    "        r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "        # Return the fitted model and the R^2 scores for training and testing sets\n",
    "        self.model = model\n",
    "        return model, (r2_train, r2_test)\n",
    "\n",
    "    def predict(self, X_new):\n",
    "        return self.model.predict(X_new)\n",
    "\n",
    "\n",
    "\n",
    "class NeuralNetModelBuilder:\n",
    "    def __init__(self, data, outcome, covariates):\n",
    "        self.data = data\n",
    "        self.outcome = outcome\n",
    "        self.covariates = covariates\n",
    "\n",
    "    def fit_neural_net(self, hidden_layer_sizes=(100, ), activation='relu', solver='adam', test_size=0.2, random_state=None, max_iter=500):\n",
    "        # Extract the X (covariates) and y (outcome) from the data\n",
    "        X = self.data[self.covariates]\n",
    "        y = self.data[self.outcome]\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "        model = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('regressor', MLPRegressor(hidden_layer_sizes=hidden_layer_sizes, activation=activation, solver=solver, max_iter=max_iter, random_state=random_state))\n",
    "        ])\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "        # Predict the outcome on the training and testing data\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        r2_train = r2_score(y_train, y_pred_train)\n",
    "        r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "        # Return the fitted model and the R^2 scores for training and testing sets\n",
    "        self.model = model\n",
    "        return model, (r2_train, r2_test)\n",
    "\n",
    "    def predict(self, X_new):\n",
    "        return self.model.predict(X_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "class WBModel:\n",
    "    \"\"\" if binarization_threshold is None, leave the treatment column as is\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 data: pd.DataFrame,\n",
    "                 treatment: str,\n",
    "                 outcome: str,\n",
    "                 separating_set: List[str],\n",
    "                 binarization_threshold: Union[float, None]=None,\n",
    "                 name: str=\"\"):\n",
    "        self.name = name\n",
    "        self.data = data.copy()\n",
    "        if isinstance(treatment, str) and treatment in self.data.columns:\n",
    "            self.treatment = treatment\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"treatment not in data or treatment not a string \"\n",
    "                \"(with the column name of the treatment)\")\n",
    "        if isinstance(outcome, str) and outcome in self.data.columns:\n",
    "            self.outcome = outcome\n",
    "        else:\n",
    "            raise ValueError(\"outcome not in data or outcome not a string\"\n",
    "                             \"(with the column name of the outcome)\")\n",
    "\n",
    "        # check that all covariates are in data\n",
    "        if not all(covariate in self.data.columns\n",
    "                   for covariate in separating_set):\n",
    "            raise ValueError(\"some covariate not in data\")\n",
    "        else:\n",
    "            self.separating_set = separating_set\n",
    "\n",
    "        self.binarization_threshold = binarization_threshold\n",
    "\n",
    "        if self.binarization_threshold is not None:\n",
    "            self.data[self.treatment] = (\n",
    "                self.data[treatment] > binarization_threshold)\n",
    "        else:\n",
    "            if set(self.data[self.treatment].unique()) != {0,1}:\n",
    "                print(\"Binarizing using median value\")\n",
    "                self.data[self.treatment] = (\n",
    "                    self.data[self.treatment] > self.data[self.treatment].median())\n",
    "\n",
    "        self.covariates_dictionary = {\n",
    "            key: value for key,value in full_dictionary.items()\n",
    "            if key in self.data.columns}\n",
    "\n",
    "        self.model_covariates=[self.treatment] + self.separating_set\n",
    "\n",
    "        # self.pre_model, self.pre_r_squared = RandomForestModelBuilder(\n",
    "        #     self.data[self.data['C'] == COVIDStatus.PRE_COVID],\n",
    "        #     self.outcome, covariates=self.model_covariates\n",
    "        #     ).fit_random_forest(n_estimators=1000)\n",
    "\n",
    "        # self.post_model, self.post_r_squared = RandomForestModelBuilder(\n",
    "        #     self.data[self.data['C'] == COVIDStatus.POST_COVID],\n",
    "        #     self.outcome, covariates=self.model_covariates\n",
    "        #     ).fit_random_forest(n_estimators=1000)\n",
    "\n",
    "        # self.pre_model, self.pre_r_squared = LinearModelBuilder(\n",
    "        #     self.data[self.data['C'] == COVIDStatus.PRE_COVID],\n",
    "        #     self.outcome, covariates=self.model_covariates\n",
    "        #     ).fit_gaussian_kernel_model()\n",
    "\n",
    "        # self.post_model, self.post_r_squared = LinearModelBuilder(\n",
    "        #     self.data[self.data['C'] == COVIDStatus.POST_COVID],\n",
    "        #     self.outcome, covariates=self.model_covariates\n",
    "        #     ).fit_gaussian_kernel_model()\n",
    "\n",
    "        self.pre_model, self.pre_r_squared = LinearModelBuilder(\n",
    "            self.data[self.data['C'] == COVIDStatus.PRE_COVID],\n",
    "            self.outcome, covariates=self.model_covariates\n",
    "            ).fit_linear_model()\n",
    "\n",
    "        self.post_model, self.post_r_squared = LinearModelBuilder(\n",
    "            self.data[self.data['C'] == COVIDStatus.POST_COVID],\n",
    "            self.outcome, covariates=self.model_covariates\n",
    "            ).fit_linear_model()\n",
    "\n",
    "        model_type_specific = {\"type\": \"linear\"}\n",
    "\n",
    "        # hidden_layer_sizes = (100, 8)\n",
    "        # max_iter = 2000\n",
    "        # self.pre_model, self.pre_r_squared = NeuralNetModelBuilder(\n",
    "        # self.data[self.data['C'] == COVIDStatus.PRE_COVID],\n",
    "        # self.outcome, covariates=self.model_covariates\n",
    "        # ).fit_neural_net(hidden_layer_sizes=hidden_layer_sizes, max_iter=max_iter)\n",
    "\n",
    "        # self.post_model, self.post_r_squared = NeuralNetModelBuilder(\n",
    "        #     self.data[self.data['C'] == COVIDStatus.POST_COVID],\n",
    "        #     self.outcome, covariates=self.model_covariates\n",
    "        #     ).fit_neural_net(hidden_layer_sizes=hidden_layer_sizes, max_iter=max_iter)\n",
    "\n",
    "        # model_type_specific = {\"model\": \"NN\",\n",
    "        #                        \"max_iter\": max_iter,\n",
    "        #                        \"hidden_layers\": list(hidden_layer_sizes)}\n",
    "\n",
    "\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "        # Step 2: Create a Path object with the folder name\n",
    "        folder_path = Path(timestamp)\n",
    "\n",
    "        # Step 3: Check if the folder exists, if not, create it\n",
    "        if not folder_path.exists():\n",
    "            folder_path.mkdir()\n",
    "            print(f\"Directory {folder_path} created.\")\n",
    "        else:\n",
    "            print(f\"Directory {folder_path} already exists.\")\n",
    "\n",
    "        results_json = {\n",
    "            \"pre_r_squared\": self.pre_r_squared,\n",
    "            \"post_r_squared\": self.post_r_squared,\n",
    "        }\n",
    "        with open(Path(folder_path, \"results.json\"), 'w') as f:\n",
    "            json.dump(results_json | model_type_specific, f, indent=4)\n",
    "\n",
    "\n",
    "    # @property\n",
    "    # def post_ace(self):\n",
    "    #     return self.post_coefficients[self.treatment]\n",
    "\n",
    "    # @property\n",
    "    # def pre_ace(self):\n",
    "    #     return self.pre_coefficients[self.treatment]\n",
    "\n",
    "    @property\n",
    "    def summary(self):\n",
    "        print(f\"pre-covid ACE: {self.pre_ace}, post_covid:{self.post_ace}\"\n",
    "              f\"pre_r_squared: {self.pre_r_squared}, post_r_squared: {self.post_r_squared}\"\n",
    "              #f\"pre_coefficients: {self.pre_coefficients}\"\n",
    "              #f\"post_coefficients:{self.post_coefficients}\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modeling yreatment:sports on outcome:gad2_score\n",
      "Binarizing using median value\n",
      "Directory 20240527_162935 created.\n",
      "pre_rsq=(0.515630819594303, 0.18240143310540635) post_r_sq=(0.732336893492419, 0.15394360819909725)\n"
     ]
    }
   ],
   "source": [
    "model_row = sets_df.iloc[32]\n",
    "\n",
    "print(f\"Modeling yreatment:{full_dictionary[model_row['treatment']]} on outcome:{full_dictionary[model_row['outcome']]}\")\n",
    "\n",
    "pass\n",
    "\n",
    "wbm = WBModel(data=df,\n",
    "            treatment=model_row['treatment'],\n",
    "            outcome=model_row['outcome'],\n",
    "            separating_set=model_row['sets'].tolist()\n",
    "            )\n",
    "\n",
    "print(f\"pre_rsq={wbm.pre_r_squared} post_r_sq={wbm.post_r_squared}\")\n",
    "        # self.pre_model, self.pre_r_squared = RandomForestModelBuilder(\n",
    "        #     self.data[self.data['C'] == COVIDStatus.PRE_COVID],\n",
    "        #     self.outcome, covariates=self.model_covariates\n",
    "        #     ).fit_random_forest(n_estimators=1000)\n",
    "\n",
    "        # self.post_model, self.post_r_squared = RandomForestModelBuilder(\n",
    "        #     self.data[self.data['C'] == COVIDStatus.POST_COVID],\n",
    "        #     self.outcome, covariates=self.model_covariates\n",
    "        #     ).fit_random_forest(n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _, model_row in sets_df.iterrows():\n",
    "#     wbm = WBModel(data=df,\n",
    "#                 treatment=model_row['treatment'],\n",
    "#                 outcome=model_row['outcome'],\n",
    "#                 separating_set=model_row['sets'].tolist()\n",
    "#                 )\n",
    "#     print(f\"pre_rsq={wbm.pre_r_squared} post_r_sq={wbm.post_r_squared}\")\n",
    "#     pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
